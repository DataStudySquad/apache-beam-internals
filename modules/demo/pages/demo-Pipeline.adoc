= Demo: Running Pipeline
:navtitle: Running Pipeline

[source,plaintext]
----
import org.apache.beam.sdk.Pipeline
val p = Pipeline.create()

// DEBUG Pipeline: Creating Pipeline#654533401

scala> :type p
org.apache.beam.sdk.Pipeline

// Create.Values is a root PTransform
// Add the root PTransform to the pipeline
import org.apache.beam.sdk.transforms.Create
val paths = Create.of("/tmp/txts/*.txt", "/tmp/csvs/*.csv")
val filepatterns = p.apply("Read File Patterns", paths)

scala> :type filepatterns
org.apache.beam.sdk.values.PCollection[String]

// DEBUG Pipeline: Adding Create.Values to Pipeline#654533401
// DEBUG CoderRegistry: Coder for java.lang.String: StringUtf8Coder
// DEBUG Pipeline: Adding Read(CreateSource) to Pipeline#654533401

scala> println(filepatterns.toString)
File Patterns/Read(CreateSource).out [PCollection]

import org.apache.beam.sdk.io.TextIO
val counts = TextIO.write().to("counts.txt")

scala> :type counts
org.apache.beam.sdk.io.TextIO.Write

// TextIO.Write is a output PTransform
assert(counts.isInstanceOf[PTransform[_, _]])

val out = filepatterns.apply("Write to counts.txt", counts)

scala> :type out
org.apache.beam.sdk.values.PDone

assert(out.getPipeline == p)

val result = p.run()

// DEBUG Pipeline: Running Pipeline#654533401 via org.apache.beam.runners.direct.DirectRunner@5f23cad5
// DEBUG TransformHierarchy: Visiting composite node RootNode
// ...
// DEBUG ExecutorServiceParallelExecutor: Pipeline has terminated. Shutting down.

val state = result.waitUntilFinish()

import org.apache.beam.sdk.PipelineResult.State
assert(state == State.DONE)
----
